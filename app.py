import tempfile
from pathlib import Path
import json
import os
import streamlit as st

# Set environment variables
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from extractor import BilingualNewspaperExtractor
from config import CONFIDENCE_THRESHOLD, KEYWORD_MIN_MATCH, NUM_WORKERS, IS_SPACES, MAX_FILE_SIZE_MB

st.set_page_config(
    page_title="EduPressAi - Educational Content Extractor",
    page_icon="ЁЯМР",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ЁЯМР EduPressAi - Educational Content Extractor")
st.caption("Upload a newspaper PDF to detect education-related articles in English & Hindi | рдЕрдВрдЧреНрд░реЗрдЬреА рдФрд░ рд╣рд┐рдВрджреА рдореЗрдВ рд╢рд┐рдХреНрд╖рд╛ рд╕рдВрдмрдВрдзреА рд▓реЗрдЦ рдЦреЛрдЬрдиреЗ рдХреЗ рд▓рд┐рдП PDF рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ")

# Health check
try:
    if st.query_params.get("health") == "check":
        st.write("OK")
        st.stop()
except AttributeError:
    try:
        params = st.experimental_get_query_params()
        if params.get("health", [None])[0] == "check":
            st.write("OK")
            st.stop()
    except:
        pass

def display_image_compatible(image_path, caption, width=400):
    """Display image with compatibility"""
    try:
        st.image(str(image_path), caption=caption, use_container_width=True)
    except TypeError:
        st.image(str(image_path), caption=caption, width=width)

def main():
    # Initialize session state
    if "results" not in st.session_state:
        st.session_state.results = None
    if "uploaded_file_name" not in st.session_state:
        st.session_state.uploaded_file_name = None
    if "processing_complete" not in st.session_state:
        st.session_state.processing_complete = False

    with st.sidebar:
        st.header("тЪЩя╕П Settings | рд╕реЗрдЯрд┐рдВрдЧреНрд╕")
        
        st.info("ЁЯМР **Bilingual Support** | **рджреНрд╡рд┐рднрд╛рд╖реА рд╕рдорд░реНрдерди**")
        st.write("тАв English articles | рдЕрдВрдЧреНрд░реЗрдЬреА рд▓реЗрдЦ")
        st.write("тАв Hindi articles | рд╣рд┐рдВрджреА рд▓реЗрдЦ")
        st.write("тАв Fast processing | рддреЗрдЬрд╝ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг")
        
        conf_threshold = st.slider(
            "YOLO Confidence | YOLO рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛",
            0.5, 0.95,
            value=0.82,
            step=0.01,
            help="Higher values = more precise detection | рдЙрдЪреНрдЪ рдорд╛рди = рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рдкрд╣рдЪрд╛рди"
        )

        min_keywords = st.slider(
            "Min Keywords | рдиреНрдпреВрдирддрдо рдХреАрд╡рд░реНрдб",
            1, 3,
            value=1,
            step=1,
            help="Minimum education keywords required | рдЖрд╡рд╢реНрдпрдХ рдиреНрдпреВрдирддрдо рд╢рд┐рдХреНрд╖рд╛ рдХреАрд╡рд░реНрдб"
        )

        save_crops = st.checkbox(
            "Save article crops | рд▓реЗрдЦ рдХреНрд░реЙрдк рд╕реЗрд╡ рдХрд░реЗрдВ",
            value=False,
            help="Save cropped images of detected articles | рдкрд╣рдЪрд╛рдиреЗ рдЧрдП рд▓реЗрдЦреЛрдВ рдХреА рдХреНрд░реЙрдк рдХреА рдЧрдИ рдЫрд╡рд┐рдпрд╛рдВ рд╕рд╣реЗрдЬреЗрдВ"
        )

        st.markdown("---")
        st.markdown("ЁЯЪА **Powered by | рджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рдд:**")
        st.markdown("тАв Bilingual YOLO v8 | рджреНрд╡рд┐рднрд╛рд╖реА YOLO v8")
        st.markdown("тАв Tesseract OCR (En+Hi)")
        st.markdown("тАв DistilBART + Extractive Summarization")

        st.info("ЁЯТб **Performance Tips | рдкреНрд░рджрд░реНрд╢рди рд╕реБрдЭрд╛рд╡:**")
        st.write("тАв Use clear PDFs under 15MB | 15MB рд╕реЗ рдХрдо рдХреЗ рд╕реНрдкрд╖реНрдЯ PDF рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ")
        st.write("тАв Both languages supported | рджреЛрдиреЛрдВ рднрд╛рд╖рд╛рдПрдВ рд╕рдорд░реНрдерд┐рдд рд╣реИрдВ")

    # File uploader
    uploaded_pdf = st.file_uploader(
        f"Upload newspaper PDF (max {MAX_FILE_SIZE_MB}MB) | рдЕрдЦрд╝рдмрд╛рд░ PDF рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ",
        type=["pdf"],
        help=f"Select a clear newspaper PDF file | рд╕реНрдкрд╖реНрдЯ рдЕрдЦрдмрд╛рд░ PDF рдлрд╝рд╛рдЗрд▓ рдХрд╛ рдЪрдпрди рдХрд░реЗрдВ"
    )

    # File validation
    if uploaded_pdf is not None:
        file_size_mb = uploaded_pdf.size / (1024 * 1024)
        if file_size_mb > MAX_FILE_SIZE_MB:
            st.error(f"ЁЯУД File too large: {file_size_mb:.1f}MB | рдлрд╝рд╛рдЗрд▓ рдмрд╣реБрдд рдмрдбрд╝реА рд╣реИ")
            st.error(f"ЁЯЪл Maximum allowed: {MAX_FILE_SIZE_MB}MB | рдЕрдзрд┐рдХрддрдо рдЕрдиреБрдорддрд┐рдд")
            return
        elif file_size_mb > MAX_FILE_SIZE_MB * 0.8:
            st.warning(f"тЪая╕П Large file ({file_size_mb:.1f}MB) - processing may take longer | рдмрдбрд╝реА рдлрд╝рд╛рдЗрд▓ - рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдореЗрдВ рдЕрдзрд┐рдХ рд╕рдордп рд▓рдЧ рд╕рдХрддрд╛ рд╣реИ")
        else:
            st.success(f"тЬЕ File ready: {file_size_mb:.1f}MB | рдлрд╝рд╛рдЗрд▓ рддреИрдпрд╛рд░ рд╣реИ")

        st.session_state.uploaded_file_name = uploaded_pdf.name

    # Main extraction button
    extract_button = st.button(
        "ЁЯЪА Extract Bilingual Education Articles | рджреНрд╡рд┐рднрд╛рд╖реА рд╢рд┐рдХреНрд╖рд╛ рд▓реЗрдЦ рдирд┐рдХрд╛рд▓реЗрдВ",
        type="primary",
        disabled=uploaded_pdf is None
    )

    # Processing
    if extract_button and uploaded_pdf is not None:
        st.session_state.results = None
        st.session_state.processing_complete = False

        # Save uploaded file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_pdf.read())
            tmp_path = tmp.name

        # Initialize extractor
        with st.spinner("ЁЯФз Loading bilingual AI models... | рджреНрд╡рд┐рднрд╛рд╖реА AI рдореЙрдбрд▓ рд▓реЛрдб рд╣реЛ рд░рд╣реЗ рд╣реИрдВ..."):
            try:
                extractor = BilingualNewspaperExtractor(
                    min_keyword_matches=min_keywords,
                    confidence_threshold=conf_threshold,
                    num_workers=NUM_WORKERS,
                    save_crops=save_crops,
                )
            except Exception as e:
                st.error(f"тЭМ Failed to load models: {str(e)} | рдореЙрдбрд▓ рд▓реЛрдб рдХрд░рдиреЗ рдореЗрдВ рд╡рд┐рдлрд▓")
                return

        # Processing with progress
        progress_bar = st.progress(0)
        status_text = st.empty()

        # Replace the processing section with this updated version:
        try:
            status_text.text("ЁЯУД Converting PDF pages at 180 DPI... | 180 DPI рдкрд░ PDF рдкреГрд╖реНрда рдкрд░рд┐рд╡рд░реНрддрд┐рдд рдХрд░ рд░рд╣реЗ рд╣реИрдВ...")
            progress_bar.progress(20)
        
            status_text.text("ЁЯОп Detecting articles with bilingual YOLO... | рджреНрд╡рд┐рднрд╛рд╖реА YOLO рд╕реЗ рд▓реЗрдЦ рдЦреЛрдЬ рд░рд╣реЗ рд╣реИрдВ...")
            progress_bar.progress(40)
        
            status_text.text("ЁЯУЭ Extracting bilingual text from all pages... | рд╕рднреА рдкреГрд╖реНрдареЛрдВ рд╕реЗ рджреНрд╡рд┐рднрд╛рд╖реА рдЯреЗрдХреНрд╕реНрдЯ рдирд┐рдХрд╛рд▓ рд░рд╣реЗ рд╣реИрдВ...")
            progress_bar.progress(60)
        
            status_text.text("ЁЯза Analyzing education content across all pages... | рд╕рднреА рдкреГрд╖реНрдареЛрдВ рдореЗрдВ рд╢рд┐рдХреНрд╖рд╛ рд╕рд╛рдордЧреНрд░реА рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг...")
            progress_bar.progress(80)
        
            # Process the PDF
            results = extractor.process_newspaper(tmp_path)
            
            progress_bar.progress(100)
            status_text.text("тЬЕ All pages processed successfully! | рд╕рднреА рдкреГрд╖реНрда рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рдкреНрд░рд╕рдВрд╕реНрдХрд░рд┐рдд!")


            # Store results
            st.session_state.results = results
            st.session_state.processing_complete = True

            # Cleanup
            try:
                os.unlink(tmp_path)
            except:
                pass

            progress_bar.empty()
            status_text.empty()

        except Exception as e:
            st.error(f"тЭМ Processing failed: {str(e)} | рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рд╡рд┐рдлрд▓")
            st.info("This might be due to: | рдпрд╣ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ:")
            st.info("тАв File complexity | рдлрд╝рд╛рдЗрд▓ рдЬрдЯрд┐рд▓рддрд╛")
            st.info("тАв Memory limitations | рдореЗрдореЛрд░реА рд╕реАрдорд╛")
            st.info("тАв Model loading issues | рдореЙрдбрд▓ рд▓реЛрдбрд┐рдВрдЧ рд╕рдорд╕реНрдпрд╛рдПрдВ")
            progress_bar.empty()
            status_text.empty()
            try:
                os.unlink(tmp_path)
            except:
                pass
            return

    # Display results
    if st.session_state.results is not None and st.session_state.processing_complete:
        results = st.session_state.results
        stats = results.get("processing_stats", {})

        # Summary metrics
        st.subheader("ЁЯУК Results Summary | рдкрд░рд┐рдгрд╛рдо рд╕рд╛рд░рд╛рдВрд╢")
        col1, col2, col3, col4 = st.columns(4)

        col1.metric("ЁЯУД Pages | рдкреГрд╖реНрда", stats.get("total_pages", 0))
        col2.metric("ЁЯФН Detected | рдкрд╣рдЪрд╛рдиреЗ рдЧрдП", stats.get("total_articles_detected", 0))
        col3.metric("ЁЯОУ Education | рд╢рд┐рдХреНрд╖рд╛", stats.get("education_articles_found", 0))
        col4.metric("ЁЯМР Languages | рднрд╛рд╖рд╛рдПрдВ", f"EN: {stats.get('english_articles', 0)} | HI: {stats.get('hindi_articles', 0)}")

        st.info("тЪб **Bilingual Processing** | рджреНрд╡рд┐рднрд╛рд╖реА рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг: Optimized for HuggingFace Spaces")

        # Education articles display
        articles = results.get("education_articles", [])
        if articles:
            st.subheader(f"ЁЯОУ Education Articles Found ({len(articles)}) | рдкрд╛рдП рдЧрдП рд╢рд┐рдХреНрд╖рд╛ рд▓реЗрдЦ")

            # Language filter
            col1, col2 = st.columns(2)
            with col1:
                language_filter = st.selectbox(
                    "ЁЯМР Filter by language | рднрд╛рд╖рд╛ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдлрд╝рд┐рд▓реНрдЯрд░ рдХрд░реЗрдВ:",
                    ["All | рд╕рднреА", "English | рдЕрдВрдЧреНрд░реЗрдЬреА", "Hindi | рд╣рд┐рдВрджреА"],
                    index=0
                )

            with col2:
                min_confidence = st.slider("ЁЯУК Minimum confidence | рдиреНрдпреВрдирддрдо рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛", 0.0, 1.0, 0.0, 0.05)

            # Apply filters
            filtered_articles = articles
            if language_filter == "English | рдЕрдВрдЧреНрд░реЗрдЬреА":
                filtered_articles = [a for a in articles if a.get('language', 'en') == 'en']
            elif language_filter == "Hindi | рд╣рд┐рдВрджреА":
                filtered_articles = [a for a in articles if a.get('language', 'en') == 'hi']

            if min_confidence > 0:
                filtered_articles = [a for a in articles if a.get('confidence', 0) >= min_confidence]

            if not filtered_articles:
                st.info("ЁЯФН No articles match your filter criteria | рдХреЛрдИ рд▓реЗрдЦ рдЖрдкрдХреЗ рдлрд╝рд┐рд▓реНрдЯрд░ рдорд╛рдирджрдВрдб рд╕реЗ рдореЗрд▓ рдирд╣реАрдВ рдЦрд╛рддрд╛")

            # Article display
            for i, article in enumerate(filtered_articles, 1):
                confidence = article.get('confidence', 0)
                language = article.get('language', 'en')
                lang_emoji = "ЁЯЗоЁЯЗ│" if language == 'hi' else "ЁЯЗ║ЁЯЗ╕"

                # Confidence indicator
                if confidence > 0.8:
                    conf_emoji = "ЁЯЯв"
                elif confidence > 0.6:
                    conf_emoji = "ЁЯЯб"
                else:
                    conf_emoji = "ЁЯФ┤"

                with st.expander(f"{conf_emoji} {lang_emoji} Article {i} - Page {article['page']} (conf: {confidence:.2f})"):
                    # Metadata
                    meta_cols = st.columns(4)
                    keywords = article.get('keywords_found', [])[:5]
                    meta_cols[0].write(f"**ЁЯП╖я╕П Keywords:** {', '.join(keywords)}")
                    meta_cols[1].write(f"**ЁЯУЭ Length:** {article.get('text_length', 0)} chars")
                    meta_cols[2].write(f"**ЁЯМР Language | рднрд╛рд╖рд╛:** {'Hindi | рд╣рд┐рдВрджреА' if language == 'hi' else 'English | рдЕрдВрдЧреНрд░реЗрдЬреА'}")
                    meta_cols[3].write(f"**ЁЯУН Position:** Page {article['page']}")

                    # Show crop image
                    if article.get("crop_path") and Path(article["crop_path"]).exists():
                        display_image_compatible(article["crop_path"], "ЁЯЦ╝я╕П Article Crop", width=600)

                    # AI Summary
                    st.markdown("**ЁЯдЦ AI Summary | AI рд╕рд╛рд░рд╛рдВрд╢:**")
                    summary = article.get("summary", "No summary available | рдХреЛрдИ рд╕рд╛рд░рд╛рдВрд╢ рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ")
                    st.write(summary)

                    # Full text
                    with st.expander("ЁЯУД View full extracted text | рдкреВрд░реНрдг рдирд┐рдХрд╛рд▓рд╛ рдЧрдпрд╛ рдЯреЗрдХреНрд╕реНрдЯ рджреЗрдЦреЗрдВ"):
                        full_text = article.get("full_text", "No text extracted")
                        if full_text and len(full_text) > 20:
                            st.text_area(
                                label=f"Article {i} Text",
                                value=full_text,
                                height=150,
                                key=f"text_{article['page']}_{i}",
                                label_visibility="collapsed"
                            )
                        else:
                            st.info("ЁЯУЭ No readable text could be extracted | рдХреЛрдИ рдкрдардиреАрдп рдЯреЗрдХреНрд╕реНрдЯ рдирд┐рдХрд╛рд▓рд╛ рдирд╣реАрдВ рдЬрд╛ рд╕рдХрд╛")

        else:
            st.info("ЁЯФН No education articles found | рдХреЛрдИ рд╢рд┐рдХреНрд╖рд╛ рд▓реЗрдЦ рдирд╣реАрдВ рдорд┐рд▓рд╛")
            st.info("Try adjusting the confidence threshold | рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛ рд╕реАрдорд╛ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВ")

        # Download results
        st.subheader("ЁЯТ╛ Download Results | рдкрд░рд┐рдгрд╛рдо рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ")
        json_data = json.dumps(results, indent=2, ensure_ascii=False).encode("utf-8")
        filename = f"bilingual_education_articles_{st.session_state.uploaded_file_name or 'results'}.json"

        st.download_button(
            "ЁЯУе Download JSON Results | JSON рдкрд░рд┐рдгрд╛рдо рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
            data=json_data,
            file_name=filename,
            mime="application/json"
        )

        # Reset button
        if st.button("ЁЯФД Process Another PDF | рдЕрдиреНрдп PDF рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХрд░реЗрдВ"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]

    # Footer
    st.markdown("---")
    st.markdown("тЪб Bilingual performance optimized for HuggingFace Spaces | HuggingFace рд╕реНрдкреЗрд╕реЗрд╕ рдХреЗ рд▓рд┐рдП рджреНрд╡рд┐рднрд╛рд╖реА рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рд┐рдд")

if __name__ == "__main__":
    main()
